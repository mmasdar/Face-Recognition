{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "coursera": {
      "course_slug": "convolutional-neural-networks",
      "graded_item_id": "IaknP",
      "launcher_item_id": "5UMr4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    },
    "colab": {
      "name": "Face Recognition",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcxm9tLAcpo1",
        "colab_type": "text"
      },
      "source": [
        "# Face Recognition\n",
        "\n",
        "In this notebook we will discuss Face Recognition. Its application in the real world is very much. Over time, the need for face recognition systems has also increased. Some applications of Face Recognition are in the automatic attendance system based on the face images of each staff in the office. other than that it can also be used to count the number of visitors in a store, it can even be used to record anyone who is in a place accurately. In this notebook, Many of the ideas presented here are from [FaceNet](https://arxiv.org/pdf/1503.03832.pdf).  \n",
        ".\n",
        "\n",
        "Basically, Face Recognition covers 2 things. namely Face Verification and Face Recognition itself. \n",
        "\n",
        "- **Face Verification** - Face verification is a mechanism in the algorithm that allows us to distinguish whether an image is a face or not. This uses the concept of comparing images in data with images used for 1: 1 testing\n",
        "- **Face Recognition** - Face Recognition works by comparing the testing image with the amount of data stored in the system. So Face Recognition can find out \"whose face is in this testing data?\". So the logic used is a comparison of face testing with a number of data in the system. 1: n data in the system."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWNBkZJ2cppD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
        "from keras.models import Model\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
        "from keras.layers.merge import Concatenate\n",
        "from keras.layers.core import Lambda, Flatten, Dense\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.engine.topology import Layer\n",
        "from keras import backend as K\n",
        "K.set_image_data_format('channels_first')\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from numpy import genfromtxt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import fr_utils\n",
        "from fr_utils import *\n",
        "from inception_blocks_v2 import *\n",
        "\n",
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "np.set_printoptions(threshold=np.nan)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsUN_GFScppZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FRmodel = faceRecoModel(input_shape=(3, 96, 96))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_gb7yjxcppg",
        "colab_type": "code",
        "colab": {},
        "outputId": "79f8d3e3-833d-471d-9697-257aebbac155"
      },
      "source": [
        "print(\"Total Params:\", FRmodel.count_params())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Params: 3743280\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHtiwQ7-cpps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
        "      \n",
        "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
        "    \n",
        "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), axis = -1)\n",
        "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), axis = -1)\n",
        "    basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), alpha) \n",
        "    loss = tf.reduce_sum(tf.maximum(basic_loss, 0))\n",
        "    \n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5u9MRYHcppz",
        "colab_type": "code",
        "colab": {},
        "outputId": "e0f1df28-2065-4843-f2c8-d3d0d11d39ab"
      },
      "source": [
        "with tf.Session() as test:\n",
        "    tf.set_random_seed(1)\n",
        "    y_true = (None, None, None)\n",
        "    y_pred = (tf.random_normal([3, 128], mean=6, stddev=0.1, seed = 1),\n",
        "              tf.random_normal([3, 128], mean=1, stddev=1, seed = 1),\n",
        "              tf.random_normal([3, 128], mean=3, stddev=4, seed = 1))\n",
        "    loss = triplet_loss(y_true, y_pred)\n",
        "    \n",
        "    print(\"loss = \" + str(loss.eval()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss = 528.143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_r8CEFJLcpp8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FRmodel.compile(optimizer = 'adam', loss = triplet_loss, metrics = ['accuracy'])\n",
        "load_weights_from_FaceNet(FRmodel)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXumu4PjcpqL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Database from staff face images\n",
        "database = {}\n",
        "database[\"danielle\"] = img_to_encoding(\"images/danielle.png\", FRmodel)\n",
        "database[\"younes\"] = img_to_encoding(\"images/younes.jpg\", FRmodel)\n",
        "database[\"tian\"] = img_to_encoding(\"images/tian.jpg\", FRmodel)\n",
        "database[\"andrew\"] = img_to_encoding(\"images/andrew.jpg\", FRmodel)\n",
        "database[\"kian\"] = img_to_encoding(\"images/kian.jpg\", FRmodel)\n",
        "database[\"dan\"] = img_to_encoding(\"images/dan.jpg\", FRmodel)\n",
        "database[\"sebastiano\"] = img_to_encoding(\"images/sebastiano.jpg\", FRmodel)\n",
        "database[\"bertrand\"] = img_to_encoding(\"images/bertrand.jpg\", FRmodel)\n",
        "database[\"kevin\"] = img_to_encoding(\"images/kevin.jpg\", FRmodel)\n",
        "database[\"felix\"] = img_to_encoding(\"images/felix.jpg\", FRmodel)\n",
        "database[\"benoit\"] = img_to_encoding(\"images/benoit.jpg\", FRmodel)\n",
        "database[\"arnaud\"] = img_to_encoding(\"images/arnaud.jpg\", FRmodel)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_buNT8EcpqS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def verify(image_path, identity, database, model):\n",
        "    encoding = img_to_encoding(image_path, model)\n",
        "\n",
        "    dist = np.linalg.norm(encoding - database[identity])\n",
        "    \n",
        "    if dist < 0.7:\n",
        "        print(\"It's \" + str(identity) + \", welcome home!\")\n",
        "        door_open = True\n",
        "    else:\n",
        "        print(\"It's not \" + str(identity) + \", please go away\")\n",
        "        door_open = False\n",
        "        \n",
        "        \n",
        "    return dist, door_open"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUyWxvPKcpqY",
        "colab_type": "code",
        "colab": {},
        "outputId": "d2fe7df1-770e-40c7-da84-ebe47b4c1cc7"
      },
      "source": [
        "verify(\"images/camera_0.jpg\", \"younes\", database, FRmodel)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "It's younes, welcome home!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.65939289, True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xcoq2lsIcpqi",
        "colab_type": "code",
        "colab": {},
        "outputId": "2a3ca9d4-6db6-4dc5-9011-bb599b429afe"
      },
      "source": [
        "verify(\"images/camera_2.jpg\", \"kian\", database, FRmodel)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "It's not kian, please go away\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.86224014, False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "453gCUkKcpqq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def who_is_it(image_path, database, model):\n",
        "\n",
        "    encoding = img_to_encoding(image_path, model)\n",
        "    \n",
        "    min_dist = 100\n",
        "    \n",
        "    for (name, db_enc) in database.items():\n",
        "        \n",
        "        dist = np.linalg.norm(encoding - db_enc)\n",
        "\n",
        "        if dist < min_dist:\n",
        "            min_dist = dist\n",
        "            identity = name\n",
        "    \n",
        "    if min_dist > 0.7:\n",
        "        print(\"Not in the database.\")\n",
        "    else:\n",
        "        print (\"it's \" + str(identity) + \", the distance is \" + str(min_dist))\n",
        "        \n",
        "    return min_dist, identity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "oxS8QssHcpqy",
        "colab_type": "code",
        "colab": {},
        "outputId": "bf3a9e6e-507e-4d29-a80c-9923d6953517"
      },
      "source": [
        "who_is_it(\"images/camera_0.jpg\", database, FRmodel)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "it's younes, the distance is 0.659393\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.65939289, 'younes')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QT5fwEkHcprA",
        "colab_type": "text"
      },
      "source": [
        "### References:\n",
        "\n",
        "- Florian Schroff, Dmitry Kalenichenko, James Philbin (2015). [FaceNet: A Unified Embedding for Face Recognition and Clustering](https://arxiv.org/pdf/1503.03832.pdf)\n",
        "- Yaniv Taigman, Ming Yang, Marc'Aurelio Ranzato, Lior Wolf (2014). [DeepFace: Closing the gap to human-level performance in face verification](https://research.fb.com/wp-content/uploads/2016/11/deepface-closing-the-gap-to-human-level-performance-in-face-verification.pdf) \n",
        "- The pretrained model we use is inspired by Victor Sy Wang's implementation and was loaded using his code: https://github.com/iwantooxxoox/Keras-OpenFace.\n",
        "- Our implementation also took a lot of inspiration from the official FaceNet github repository: https://github.com/davidsandberg/facenet \n"
      ]
    }
  ]
}